use anyhow::{Context, Result};
use colored::*;
use redb::{Database, TableDefinition, WriteTransaction, ReadableTable, ReadableDatabase};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{self, File};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::{SystemTime, UNIX_EPOCH};

// Cache Configuration
pub const CACHE_DIR: &str = ".veghcache";
const CACHE_DB_FILE: &str = "cache.redb";
const JSON_CACHE_FILE: &str = "index.json";

// Redb Tables - v2 Schema
const TABLE_DATA_V2_A: TableDefinition<&str, &[u8]> = TableDefinition::new("data_v2_A");
const TABLE_DATA_V2_B: TableDefinition<&str, &[u8]> = TableDefinition::new("data_v2_B");
const TABLE_INODES_V2_A: TableDefinition<u64, &str> = TableDefinition::new("inodes_v2_A");
const TABLE_INODES_V2_B: TableDefinition<u64, &str> = TableDefinition::new("inodes_v2_B");
const TABLE_META: TableDefinition<&str, &str> = TableDefinition::new("meta");

// Cache Entry Structure
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct FileCacheEntry {
    pub size: u64,
    pub modified: u64,
    
    // Improved Change Detection
    #[serde(default)]
    pub ctime_sec: i64,
    #[serde(default)]
    pub ctime_nsec: u32,
    #[serde(default)]
    pub device_id: u64,
    #[serde(default)]
    pub inode: u64,
    
    // GC Retention
    #[serde(default)]
    pub last_seen: u64,

    // Binary Hashes
    pub hash: Option<[u8; 32]>,
    #[serde(default)]
    pub chunks: Option<Vec<[u8; 32]>>,
    #[serde(default)]
    pub sparse_hash: Option<[u8; 32]>,
}

// FV3 Manifest Structures (Unchanged - Needs Hex Strings for JSON)
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ManifestEntry {
    pub path: String,
    pub hash: String,
    pub size: u64,
    pub modified: u64,
    #[serde(default)]
    pub mode: u32, // Permissions
    #[serde(default)]
    pub chunks: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Debug, Clone, Default)]
pub struct SnapshotManifest {
    pub entries: Vec<ManifestEntry>,
}

// Legacy Cache for Migration (Kept only for JSON migration)
// Note: This matches the OLD FileCacheEntry structure for deserialization purposes only.
// If we encounter a JSON file, we will try to migrate it, but since we are changing binary formats
// drastically, we might just skip complex migration for now or map it best effort.
// The user prompt asked for upgrades, so we prioritize the new struct. 
// A "cold cache" start is acceptable for major version bumps in dev tools.
#[derive(Serialize, Deserialize, Debug, Default)]
struct LegacyVeghCache {
    pub last_snapshot: i64,
    pub files: HashMap<String, LegacyFileCacheEntry>,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
struct LegacyFileCacheEntry {
    pub size: u64,
    pub modified: u64,
    pub inode: u64,
    pub hash: Option<String>,
    pub chunks: Option<Vec<String>>,
    pub sparse_hash: Option<String>,
}

pub struct CacheDB {
    db: Arc<Database>,
    active_slot: String, // "A" or "B"
    txn: Option<WriteTransaction>,
}

impl CacheDB {
    pub fn open(source: &Path) -> Result<Self> {
        let cache_dir = source.join(CACHE_DIR);
        if !cache_dir.exists() {
            fs::create_dir(&cache_dir).context("Failed to create cache dir")?;
            let gitignore_path = cache_dir.join(".gitignore");
            if !gitignore_path.exists() {
                 let content = "# Generated by Vegh\n*\n";
                 let _ = fs::write(gitignore_path, content);
            }
        }

        let db_path = cache_dir.join(CACHE_DB_FILE);
        let db = Database::create(&db_path)?;
        let db = Arc::new(db);

        // Determine active slot
        let active_slot = {
            let read_txn = db.begin_read()?;
            if let Ok(table) = read_txn.open_table(TABLE_META) {
                table.get("active_slot")?
                    .map(|v| v.value().to_string())
                    .unwrap_or_else(|| "A".to_string())
            } else {
                "A".to_string()
            }
        };

        let mut cache_db = Self {
            db: db.clone(),
            active_slot: active_slot.clone(),
            txn: Some(db.begin_write()?),
        };

        // Migration Logic (JSON only - binary table names changed so old data is ignored)
        let json_path = cache_dir.join(JSON_CACHE_FILE);
        if json_path.exists() {
            cache_db.migrate_legacy_json(&json_path)?;
        }

        // Prepare the "Next" tables (clear them)
        cache_db.prepare_next_tables()?;

        Ok(cache_db)
    }

    fn prepare_next_tables(&mut self) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        let txn = self.txn.as_mut().unwrap(); // Safe as we init with Some

        if next_slot == "A" {
            // Delete tables to clear them
            let _ = txn.delete_table(TABLE_DATA_V2_A);
            let _ = txn.delete_table(TABLE_INODES_V2_A);
            // Re-create empty tables
            txn.open_table(TABLE_DATA_V2_A)?;
            txn.open_table(TABLE_INODES_V2_A)?;
        } else {
            let _ = txn.delete_table(TABLE_DATA_V2_B);
            let _ = txn.delete_table(TABLE_INODES_V2_B);
            txn.open_table(TABLE_DATA_V2_B)?;
            txn.open_table(TABLE_INODES_V2_B)?;
        }

        Ok(())
    }

    fn migrate_legacy_json(&mut self, path: &Path) -> Result<()> {
        println!("{} Migrating JSON cache to Embedded DB...", "ðŸ“¦".cyan());
        if let Ok(file) = File::open(path) {
            if let Ok(cache) = serde_json::from_reader::<_, LegacyVeghCache>(file) {
                 // Best effort conversion
                 let mut converted_files = HashMap::new();
                 let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
                 
                 for (k, v) in cache.files {
                     // Try to decode hex strings to bytes
                     let hash_bytes = v.hash.and_then(|h| hex::decode(h).ok())
                        .and_then(|v| v.try_into().ok());
                     
                     let sparse_bytes = v.sparse_hash.and_then(|h| hex::decode(h).ok())
                        .and_then(|v| v.try_into().ok());
                        
                     let chunks_bytes = v.chunks.map(|chunks| {
                         chunks.into_iter()
                             .filter_map(|h| hex::decode(h).ok().and_then(|v| v.try_into().ok()))
                             .collect()
                     });

                     let new_entry = FileCacheEntry {
                         size: v.size,
                         modified: v.modified,
                         inode: v.inode,
                         ctime_sec: 0,
                         ctime_nsec: 0,
                         device_id: 0,
                         last_seen: now,
                         hash: hash_bytes,
                         chunks: chunks_bytes,
                         sparse_hash: sparse_bytes,
                     };
                     converted_files.insert(k, new_entry);
                 }
                 self.import_map(converted_files)?;
            }
        }
        let _ = fs::remove_file(path);
        Ok(())
    }

    fn import_map(&mut self, files: HashMap<String, FileCacheEntry>) -> Result<()> {
        let txn = self.txn.as_mut().unwrap();
        
        // Write to whichever slot is active or next?
        // Actually, this is only called during OPEN, and we want to populate the ACTIVE slot
        // so `get` calls work.
        if self.active_slot == "A" {
            let mut data = txn.open_table(TABLE_DATA_V2_A)?;
            let mut inodes = txn.open_table(TABLE_INODES_V2_A)?;
            for (path, entry) in files {
                let bytes = bincode::serialize(&entry)?;
                data.insert(path.as_str(), bytes.as_slice())?;
                if entry.inode > 0 {
                    inodes.insert(entry.inode, path.as_str())?;
                }
            }
        } else {
            let mut data = txn.open_table(TABLE_DATA_V2_B)?;
            let mut inodes = txn.open_table(TABLE_INODES_V2_B)?;
            for (path, entry) in files {
                let bytes = bincode::serialize(&entry)?;
                data.insert(path.as_str(), bytes.as_slice())?;
                if entry.inode > 0 {
                    inodes.insert(entry.inode, path.as_str())?;
                }
            }
        }
        Ok(())
    }

    // Get entry from ACTIVE table
    pub fn get(&self, path: &str) -> Result<Option<FileCacheEntry>> {
        if let Some(txn) = &self.txn {
            let bytes_opt = if self.active_slot == "A" {
                txn.open_table(TABLE_DATA_V2_A)?.get(path)?.map(|v| v.value().to_vec())
            } else {
                txn.open_table(TABLE_DATA_V2_B)?.get(path)?.map(|v| v.value().to_vec())
            };

            if let Some(bytes) = bytes_opt {
                let entry: FileCacheEntry = bincode::deserialize(&bytes)?;
                return Ok(Some(entry));
            }
        }
        Ok(None)
    }

    // Get path by inode from ACTIVE table
    pub fn get_path_by_inode(&self, inode: u64) -> Result<Option<String>> {
        if inode == 0 { return Ok(None); }
        if let Some(txn) = &self.txn {
            let path_opt = if self.active_slot == "A" {
                txn.open_table(TABLE_INODES_V2_A)?.get(inode)?.map(|v| v.value().to_string())
            } else {
                txn.open_table(TABLE_INODES_V2_B)?.get(inode)?.map(|v| v.value().to_string())
            };
            return Ok(path_opt);
        }
        Ok(None)
    }

    // Insert into NEXT table
    pub fn insert(&mut self, path: &str, entry: &FileCacheEntry) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        let txn = self.txn.as_mut().unwrap();
        
        let bytes = bincode::serialize(entry)?;

        if next_slot == "A" {
            let mut data = txn.open_table(TABLE_DATA_V2_A)?;
            data.insert(path, bytes.as_slice())?;
            if entry.inode > 0 {
                let mut inodes = txn.open_table(TABLE_INODES_V2_A)?;
                inodes.insert(entry.inode, path)?;
            }
        } else {
            let mut data = txn.open_table(TABLE_DATA_V2_B)?;
            data.insert(path, bytes.as_slice())?;
            if entry.inode > 0 {
                let mut inodes = txn.open_table(TABLE_INODES_V2_B)?;
                inodes.insert(entry.inode, path)?;
            }
        }
        Ok(())
    }

    // Garbage Collect and Merge
    // Iterates Active table, checks entries not in Next table.
    // If they are recent enough (retention policy), copy them to Next.
    pub fn garbage_collect_and_merge(&mut self, retention_seconds: u64) -> Result<()> {
        // We cannot borrow `self.txn` mutably twice (for iterating and inserting).
        // Redb `iter()` holds a borrow on the table which holds a borrow on the txn.
        // We need to collect keys/values to copy first, or use unsafe, or just collect keys.
        // Collecting keys might be safer and simpler given memory constraints are usually fine for keys.
        // Or we can just read all entries into a Vec if not too massive.
        // Better: iterate, collect keys of items to keep. Then loop keys, read from active, write to next.
        // Actually, we can open the active table for reading via a separate read transaction?
        // No, we are inside a WriteTransaction. A WriteTransaction can open tables.
        
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        let current_slot = &self.active_slot;
        
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        let mut entries_to_keep: Vec<(String, Vec<u8>)> = Vec::new();
        
        // Scope for iteration
        {
            let txn = self.txn.as_mut().unwrap();
            let source = if current_slot == "A" { txn.open_table(TABLE_DATA_V2_A)? } else { txn.open_table(TABLE_DATA_V2_B)? };
            let dest = if next_slot == "A" { txn.open_table(TABLE_DATA_V2_A)? } else { txn.open_table(TABLE_DATA_V2_B)? };

            // We iterate source. If key not in dest, we check last_seen.
            for res in source.iter()? {
                let (k, v) = res?;
                let key_str = k.value();
                
                // If not already in Next (dest)
                if dest.get(key_str)?.is_none() {
                    let val_bytes = v.value().to_vec();
                    // Deserialize to check last_seen
                    if let Ok(entry) = bincode::deserialize::<FileCacheEntry>(&val_bytes) {
                        if now.saturating_sub(entry.last_seen) < retention_seconds {
                            entries_to_keep.push((key_str.to_string(), val_bytes));
                        }
                    }
                }
            }
        } // End scope, releasing table borrows

        // Write kept entries
        let txn = self.txn.as_mut().unwrap();
        let mut dest_data = if next_slot == "A" { txn.open_table(TABLE_DATA_V2_A)? } else { txn.open_table(TABLE_DATA_V2_B)? };
        let mut dest_inodes = if next_slot == "A" { txn.open_table(TABLE_INODES_V2_A)? } else { txn.open_table(TABLE_INODES_V2_B)? };
        
        let kept_count = entries_to_keep.len();
        if kept_count > 0 {
            println!("{} GC: Keeping {} valid entries.", "ðŸ§¹".blue(), kept_count);
        }

        for (path, bytes) in entries_to_keep {
            dest_data.insert(path.as_str(), bytes.as_slice())?;
            // Also need to restore inode mapping if it exists
             if let Ok(entry) = bincode::deserialize::<FileCacheEntry>(&bytes) {
                 if entry.inode > 0 {
                     dest_inodes.insert(entry.inode, path.as_str())?;
                 }
             }
        }

        Ok(())
    }


    // Commit changes: Swap Active <-> Next and persist
    pub fn commit(mut self) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        
        if let Some(txn) = self.txn.take() {
            {
                let mut meta = txn.open_table(TABLE_META)?;
                meta.insert("active_slot", next_slot)?;
            }
            txn.commit()?;
        }
        Ok(())
    }

    // Sync Partial (Ctrl+C): Copy unvisited from Active to Next, then Commit
    // Updated to use the new GC/Merge logic essentially (infinite retention or just copy all valid).
    // Actually, sync_partial implies we were interrupted, so we want to keep everything that was in active
    // but not yet in next, effectively "merging" the old state back so we don't lose it.
    pub fn sync_partial(mut self) -> Result<()> {
        println!("{} Syncing partial cache...", "ðŸ’¾".blue());
        
        // Use a very long retention to keep everything
        self.garbage_collect_and_merge(u64::MAX)?;
        
        self.commit()?;
        println!("{} Cache saved (Partial).", "âœ…".green());
        Ok(())
    }
}
