use anyhow::{Context, Result};
use colored::*;
use redb::{Database, TableDefinition, WriteTransaction, ReadableTable, ReadableDatabase};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{self, File};
use std::path::{Path, PathBuf};
use std::sync::Arc;

// Cache Configuration
pub const CACHE_DIR: &str = ".veghcache";
const CACHE_DB_FILE: &str = "cache.redb";
// Removed LEGACY_CACHE_FILE (index.bin.zst).
const JSON_CACHE_FILE: &str = "index.json";

// Redb Tables
// Using "double buffering" strategy for safe updates and garbage collection
// Active tables contain the last valid snapshot state
// Next tables are populated during the current run
const TABLE_DATA_A: TableDefinition<&str, &[u8]> = TableDefinition::new("data_A");
const TABLE_DATA_B: TableDefinition<&str, &[u8]> = TableDefinition::new("data_B");
const TABLE_INODES_A: TableDefinition<u64, &str> = TableDefinition::new("inodes_A");
const TABLE_INODES_B: TableDefinition<u64, &str> = TableDefinition::new("inodes_B");
const TABLE_META: TableDefinition<&str, &str> = TableDefinition::new("meta");

// Cache Entry Structure
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct FileCacheEntry {
    pub size: u64,
    pub modified: u64,
    #[serde(default)]
    pub inode: u64,
    pub hash: Option<String>,
    #[serde(default)]
    pub chunks: Option<Vec<String>>,
    #[serde(default)]
    pub sparse_hash: Option<String>,
}

// FV3 Manifest Structures (Unchanged)
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ManifestEntry {
    pub path: String,
    pub hash: String,
    pub size: u64,
    pub modified: u64,
    #[serde(default)]
    pub mode: u32, // Permissions
    #[serde(default)]
    pub chunks: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Debug, Clone, Default)]
pub struct SnapshotManifest {
    pub entries: Vec<ManifestEntry>,
}

// Legacy Cache for Migration (Kept only for JSON migration)
#[derive(Serialize, Deserialize, Debug, Default)]
struct LegacyVeghCache {
    pub last_snapshot: i64,
    pub files: HashMap<String, FileCacheEntry>,
}

pub struct CacheDB {
    db: Arc<Database>,
    active_slot: String, // "A" or "B"
    txn: Option<WriteTransaction>,
}

impl CacheDB {
    pub fn open(source: &Path) -> Result<Self> {
        let cache_dir = source.join(CACHE_DIR);
        if !cache_dir.exists() {
            fs::create_dir(&cache_dir).context("Failed to create cache dir")?;
            // [UX] Auto-generate .gitignore
            let gitignore_path = cache_dir.join(".gitignore");
            if !gitignore_path.exists() {
                 let content = "# Generated by Vegh\n*\n";
                 let _ = fs::write(gitignore_path, content);
            }
        }

        let db_path = cache_dir.join(CACHE_DB_FILE);
        let db = Database::create(&db_path)?;
        let db = Arc::new(db);

        // Determine active slot
        let active_slot = {
            let read_txn = db.begin_read()?;
            if let Ok(table) = read_txn.open_table(TABLE_META) {
                table.get("active_slot")?
                    .map(|v| v.value().to_string())
                    .unwrap_or_else(|| "A".to_string())
            } else {
                "A".to_string()
            }
        };

        let mut cache_db = Self {
            db: db.clone(),
            active_slot: active_slot.clone(),
            txn: Some(db.begin_write()?),
        };

        // Migration Logic Refined:
        // Removed check for binary legacy cache (zst).
        // Only checking for JSON cache file now.
        let json_path = cache_dir.join(JSON_CACHE_FILE);
        if json_path.exists() {
            cache_db.migrate_legacy_json(&json_path)?;
        }

        // Prepare the "Next" tables (clear them)
        cache_db.prepare_next_tables()?;

        Ok(cache_db)
    }

    fn prepare_next_tables(&mut self) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        let txn = self.txn.as_mut().unwrap(); // Safe as we init with Some

        if next_slot == "A" {
            // Delete tables to clear them
            let _ = txn.delete_table(TABLE_DATA_A);
            let _ = txn.delete_table(TABLE_INODES_A);
            // Re-create empty tables
            txn.open_table(TABLE_DATA_A)?;
            txn.open_table(TABLE_INODES_A)?;
        } else {
            let _ = txn.delete_table(TABLE_DATA_B);
            let _ = txn.delete_table(TABLE_INODES_B);
            txn.open_table(TABLE_DATA_B)?;
            txn.open_table(TABLE_INODES_B)?;
        }

        Ok(())
    }

    // Removed migrate_legacy() function which handled zstd binary files.

    fn migrate_legacy_json(&mut self, path: &Path) -> Result<()> {
        println!("{} Migrating JSON cache to Embedded DB...", "ðŸ“¦".cyan());
        if let Ok(file) = File::open(path) {
            if let Ok(cache) = serde_json::from_reader::<_, LegacyVeghCache>(file) {
                 self.import_map(cache.files)?;
            }
        }
        let _ = fs::remove_file(path);
        Ok(())
    }

    fn import_map(&mut self, files: HashMap<String, FileCacheEntry>) -> Result<()> {
        // Import into ACTIVE table (so we can use it immediately)
        // This is called inside `open`, so `txn` is available.
        // We write to `active_slot`.
        let txn = self.txn.as_mut().unwrap();
        
        if self.active_slot == "A" {
            let mut data = txn.open_table(TABLE_DATA_A)?;
            let mut inodes = txn.open_table(TABLE_INODES_A)?;
            for (path, entry) in files {
                let bytes = bincode::serialize(&entry)?;
                data.insert(path.as_str(), bytes.as_slice())?;
                if entry.inode > 0 {
                    inodes.insert(entry.inode, path.as_str())?;
                }
            }
        } else {
            let mut data = txn.open_table(TABLE_DATA_B)?;
            let mut inodes = txn.open_table(TABLE_INODES_B)?;
            for (path, entry) in files {
                let bytes = bincode::serialize(&entry)?;
                data.insert(path.as_str(), bytes.as_slice())?;
                if entry.inode > 0 {
                    inodes.insert(entry.inode, path.as_str())?;
                }
            }
        }
        Ok(())
    }

    // Get entry from ACTIVE table
    pub fn get(&self, path: &str) -> Result<Option<FileCacheEntry>> {
        if let Some(txn) = &self.txn {
            let bytes_opt = if self.active_slot == "A" {
                txn.open_table(TABLE_DATA_A)?.get(path)?.map(|v| v.value().to_vec())
            } else {
                txn.open_table(TABLE_DATA_B)?.get(path)?.map(|v| v.value().to_vec())
            };

            if let Some(bytes) = bytes_opt {
                let entry: FileCacheEntry = bincode::deserialize(&bytes)?;
                return Ok(Some(entry));
            }
        }
        Ok(None)
    }

    // Get path by inode from ACTIVE table
    pub fn get_path_by_inode(&self, inode: u64) -> Result<Option<String>> {
        if inode == 0 { return Ok(None); }
        if let Some(txn) = &self.txn {
            let path_opt = if self.active_slot == "A" {
                txn.open_table(TABLE_INODES_A)?.get(inode)?.map(|v| v.value().to_string())
            } else {
                txn.open_table(TABLE_INODES_B)?.get(inode)?.map(|v| v.value().to_string())
            };
            return Ok(path_opt);
        }
        Ok(None)
    }

    // Insert into NEXT table
    pub fn insert(&mut self, path: &str, entry: &FileCacheEntry) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        let txn = self.txn.as_mut().unwrap();
        
        let bytes = bincode::serialize(entry)?;

        if next_slot == "A" {
            let mut data = txn.open_table(TABLE_DATA_A)?;
            data.insert(path, bytes.as_slice())?;
            if entry.inode > 0 {
                let mut inodes = txn.open_table(TABLE_INODES_A)?;
                inodes.insert(entry.inode, path)?;
            }
        } else {
            let mut data = txn.open_table(TABLE_DATA_B)?;
            data.insert(path, bytes.as_slice())?;
            if entry.inode > 0 {
                let mut inodes = txn.open_table(TABLE_INODES_B)?;
                inodes.insert(entry.inode, path)?;
            }
        }
        Ok(())
    }

    // Commit changes: Swap Active <-> Next and persist
    pub fn commit(mut self) -> Result<()> {
        let next_slot = if self.active_slot == "A" { "B" } else { "A" };
        
        if let Some(txn) = self.txn.take() {
            {
                let mut meta = txn.open_table(TABLE_META)?;
                meta.insert("active_slot", next_slot)?;
            }
            txn.commit()?;
        }
        Ok(())
    }

    // Sync Partial (Ctrl+C): Copy unvisited from Active to Next, then Commit
    pub fn sync_partial(mut self) -> Result<()> {
        println!("{} Syncing partial cache...", "ðŸ’¾".blue());
        
        let txn = self.txn.as_mut().unwrap();
        
        // Open Source (Active) and Dest (Next)
        // Note: Iterating active while writing to next.
        // We need separate handles.
        
        if self.active_slot == "A" {
             // Active: A, Next: B
             let source = txn.open_table(TABLE_DATA_A)?;
             let mut dest = txn.open_table(TABLE_DATA_B)?;
             let mut inodes_dest = txn.open_table(TABLE_INODES_B)?;
             
             // Iterate source
             for res in source.iter()? {
                 let (k, v) = res?;
                 let key_str = k.value();
                 
                 // Check if key exists in dest
                 if dest.get(key_str)?.is_none() {
                     // Not visited (not in Next)
                     // Copy
                     let val_bytes = v.value().to_vec();
                     dest.insert(key_str, val_bytes.as_slice())?;
                     
                     // Inode copy
                     let entry: FileCacheEntry = bincode::deserialize(&val_bytes)?;
                     if entry.inode > 0 {
                         inodes_dest.insert(entry.inode, key_str)?;
                     }
                 }
             }
        } else {
             // Active: B, Next: A
             let source = txn.open_table(TABLE_DATA_B)?;
             let mut dest = txn.open_table(TABLE_DATA_A)?;
             let mut inodes_dest = txn.open_table(TABLE_INODES_A)?;
             
             for res in source.iter()? {
                 let (k, v) = res?;
                 let key_str = k.value();
                 
                 if dest.get(key_str)?.is_none() {
                     let val_bytes = v.value().to_vec();
                     dest.insert(key_str, val_bytes.as_slice())?;
                     
                     let entry: FileCacheEntry = bincode::deserialize(&val_bytes)?;
                     if entry.inode > 0 {
                         inodes_dest.insert(entry.inode, key_str)?;
                     }
                 }
             }
        }
        
        self.commit()?;
        println!("{} Cache saved (Partial).", "âœ…".green());
        Ok(())
    }
}